{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Graph Module Ingestion - Pre-Processing\r\n",
        "\r\n",
        "This notebook demonstrates the utility of the OEA_py class notebook, while removing the '@odata.context' column from the meeting_attendance_report table pre-ingestion. Once the column is removed, the rest of the table overwrites the original meeting_attendance_report, and proceeds to ingest as normally.\r\n",
        "\r\n",
        "The steps outlined below describe how this notebook is used to correct the Microsoft Graph Reports API module meeting_attendance_report table:\r\n",
        "- Set the workspace for where the meeting_attendance_report table is to be corrected. \r\n",
        "- Read in the original JSON landed in ```stage1/Transactional/graph_api/v1.0/meeting_attendance_report``` and remove the @odata.context column. Overwrite the JSON (and remove any additional rundate folders, as described by the method below).\r\n",
        "- 1 function is defined and used:\r\n",
        "   1. **clean_data_lake_latest**: removes any additional folders in the data lake for a location, keeping only the latest rundate folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "workspace = 'dev'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "%run OEA_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 1) set the workspace (this determines where in the data lake you'll be writing to and reading from).\r\n",
        "# You can work in 'dev', 'prod', or a sandbox with any name you choose.\r\n",
        "# For example, Sam the developer can create a 'sam' workspace and expect to find his datasets in the data lake under oea/sandboxes/sam\r\n",
        "oea.set_workspace(workspace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "# 2) read in the original meeting_attendance_report table, remove the '@odata.context' column and confirm it has been removed.\r\n",
        "df = spark.read.format('json').load(oea.to_url('stage1/Transactional/graph_api/v1.0/meeting_attendance_report'), multiline='true')\r\n",
        "df_corrected = df.select('id', 'totalParticipantCount', 'meetingStartDateTime', 'meetingEndDateTime', 'attendanceRecords')\r\n",
        "display(df_corrected.limit(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "print('Number of rows/meeting reports:')\r\n",
        "print(df_corrected.count())\r\n",
        "df_corrected.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 2.5) set the current date and time (using the correct format), and write out to the same relative same location, with a new rundate partition-folder.\r\n",
        "import datetime\r\n",
        "currentDate = datetime.datetime.now()\r\n",
        "currentDateTime = currentDate.strftime(\"%Y-%m-%d %H-%M-%S\")\r\n",
        "table_path = 'stage1/Transactional/graph_api/v1.0/meeting_attendance_report/additive_batch_data/rundate=' + currentDateTime\r\n",
        "df_corrected.write.save(oea.to_url(table_path), format='json', mode='overwrite', overwriteSchema='true')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 3) only house the latest rundate folder compared to the old data (which had the '@odata.context' column).\r\n",
        "def clean_data_lake_latest(source_path):\r\n",
        "    latest_folder = oea.get_latest_folder(source_path)\r\n",
        "    items = mssparkutils.fs.ls(oea.to_url(source_path))\r\n",
        "    for item in items:\r\n",
        "        if item.name != latest_folder:\r\n",
        "            logger.info('file removal path: ' + item.path + ' with item: ' + item.name)\r\n",
        "            oea.rm_if_exists(source_path + '/' + item.name)\r\n",
        "            logger.info('Successfully removed folder: ' + item.name + ' from path: ' + item.path)\r\n",
        "        else:\r\n",
        "            logger.info('Kept folder: ' + item.name + ' from path: ' + item.path)\r\n",
        "    logger.info('Finished cleaning data lake to house only the latest folder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "clean_data_lake_latest('stage1/Transactional/graph_api/v1.0/meeting_attendance_report/additive_batch_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 4) ad hoc work - remove the _SUCCESS file, otherwise this will throw an error when ingesting the table.\r\n",
        "table_path = 'stage1/Transactional/graph_api/v1.0/meeting_attendance_report/additive_batch_data/rundate=' + currentDateTime\r\n",
        "oea.rm_if_exists(table_path + '/_SUCCESS', False)"
      ]
    }
  ],
  "metadata": {
    "description": "Used for \"2_ingest_graph\" pipeline. Drops the @odata.context column from Graph meeting_attendance_report data originally landed.",
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}